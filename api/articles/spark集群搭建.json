{"title":"spark集群搭建","uid":"e4350603b93fc89bd9ff79c0cc5af1e6","slug":"spark集群搭建","date":"2023-02-17T12:01:41.000Z","updated":"2023-04-30T09:41:07.716Z","comments":true,"path":"api/articles/spark集群搭建.json","keywords":null,"cover":null,"content":"<p>安装带有图形化界面的centos7</p>\n<p>配置好网络：<code>vim /etc/sysconfig/network-scripts/ifcfg-ens33</code></p>\n<p>更改hostname：<code>hostnamectl set-hostname master</code></p>\n<p>连接xshell与xftp，把所需要的spark和jdk安装包传输到&#x2F;opt目录</p>\n<h1 id=\"搭建单机版集群\"><a href=\"#搭建单机版集群\" class=\"headerlink\" title=\"搭建单机版集群\"></a>搭建单机版集群</h1><h2 id=\"解压spark安装包\"><a href=\"#解压spark安装包\" class=\"headerlink\" title=\"解压spark安装包\"></a>解压spark安装包</h2><pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">tar -zxf &#x2F;opt&#x2F;spark-3.2.1-bin-hadoop2.7.tgz -C &#x2F;usr&#x2F;local</code></pre>\n\n<p>解压完成后单机版集群搭建成功</p>\n<p>进入spark安装目录的&#x2F;bin，计算Pi值</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">cd &#x2F;usr&#x2F;local&#x2F;spark-3.2.1-bin-hadoop2.7&#x2F;bin&#x2F;\n.&#x2F;run-example SparkPi 2</code></pre>\n\n<h1 id=\"搭建单机伪分式集群\"><a href=\"#搭建单机伪分式集群\" class=\"headerlink\" title=\"搭建单机伪分式集群\"></a>搭建单机伪分式集群</h1><h2 id=\"删除centos自带jdk\"><a href=\"#删除centos自带jdk\" class=\"headerlink\" title=\"删除centos自带jdk\"></a>删除centos自带jdk</h2><p>完成上一步后，需要安装jdk环境。由于带有图形化界面的centos自带openjdk，因此我们需要卸载原有的jdk，安装我们所需要的jdk文件。否则将导致jps无法执行：提示command not find</p>\n<p><a href=\"https://www.cnblogs.com/battleoutside/p/16816183.html\">[Linux执行jps命令的时候报错：-bash: jps: command not found - battleoutside - 博客园 </a></p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">rpm -qa | grep java #查看java文件</code></pre>\n\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">sudo rpm -qa | grep java | xargs rpm -e --nodeps #root权限下删除所有java文件</code></pre>\n\n<h2 id=\"安装jdk\"><a href=\"#安装jdk\" class=\"headerlink\" title=\"安装jdk\"></a>安装jdk</h2><pre class=\"line-numbers language-none\"><code class=\"language-none\">rpm -ivh jdk-8u281-linux-x64.rpm</code></pre>\n\n<p>检验</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">java -version</code></pre>\n\n<p>若出错，卸载jdk相关内容重新安装并检查：</p>\n<p>查看已安装jdk</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">rpm -qa|grep jdk</code></pre>\n\n<p>卸载列出的jdk</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">sudo yum -y remove 路径1 路径2</code></pre>\n\n<p>配置Java环境变量</p>\n<p>&#x2F;etc&#x2F;profile</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">export JAVA_HOME&#x3D;&#x2F;usr&#x2F;java&#x2F;jdk1.8.0_281-amd64\nexport PATH&#x3D;$PATH:$JAVA_HOME&#x2F;bin</code></pre>\n\n<p>记得source</p>\n<h2 id=\"spark-env-sh\"><a href=\"#spark-env-sh\" class=\"headerlink\" title=\"spark-env.sh\"></a>spark-env.sh</h2><p>进入spark安装目录下的&#x2F;conf</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">cd &#x2F;usr&#x2F;local&#x2F;spark-3.2.1-bin-hadoop2.7&#x2F;conf</code></pre>\n\n<p>将spark-env.sh.template复制为spark-env.s，y</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">cp spark-env.sh.template spark-env.sh</code></pre>\n\n<p>在文件末尾spark-env.sh添加:（在此之前需更改hostname为master,否则计算时会报错）</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">export JAVA_HOME&#x3D;&#x2F;usr&#x2F;java&#x2F;jdk1.8.0_281-amd64\nexport HADOOP_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;hadoop-3.1.4\nexport HADOOP_CONF_DIR&#x3D;&#x2F;usr&#x2F;local&#x2F;hadoop-3.1.4&#x2F;etc&#x2F;hadoop\nexport SPARK_MASTER_IP&#x3D;master\nexport SPARK_LOCAL_IP&#x3D;master</code></pre>\n\n<h2 id=\"启动hadoop集群\"><a href=\"#启动hadoop集群\" class=\"headerlink\" title=\"启动hadoop集群\"></a>启动hadoop集群</h2><p>切换到spark安装目录下的&#x2F;sbin目录</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">cd &#x2F;usr&#x2F;local&#x2F;spark-3.2.1-bin-hadoop2.7&#x2F;sbin</code></pre>\n\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">.&#x2F;start-all.sh</code></pre>\n\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">jps &#x2F;&#x2F;若未安装jdk则显示command not found</code></pre>\n\n<p>进入spark安装目录的&#x2F;bin，计算Pi值</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">cd &#x2F;usr&#x2F;local&#x2F;spark-3.2.1-bin-hadoop2.7&#x2F;bin&#x2F;\n.&#x2F;run-example SparkPi 2</code></pre>\n\n<h1 id=\"搭建完全分布式集群\"><a href=\"#搭建完全分布式集群\" class=\"headerlink\" title=\"搭建完全分布式集群\"></a>搭建完全分布式集群</h1><p> 首先完成hadoop集群的搭建，一个master、两个slave</p>\n<p>配置环境变量：</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">vim &#x2F;etc&#x2F;profile</code></pre>\n\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">export SPARK_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;spark-3.2.1-bin-hadoop2.7\nexport PATH&#x3D;$PATH:$SPARK_HOME&#x2F;bin</code></pre>\n\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">source &#x2F;etc&#x2F;profile</code></pre>\n\n\n\n<p>修改spark-env.sh，注意删除或注释上单机伪分布集群的配置，不然jps：slave的worker不启动</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">cd $SPARK_HOME&#x2F;conf</code></pre>\n\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">cp spark-env.sh.template spark-env.sh</code></pre>\n\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">export JAVA_HOME&#x3D;&#x2F;usr&#x2F;java&#x2F;jdk1.8.0_281-amd64\nexport HADOOP_CONF_DIR&#x3D;&#x2F;usr&#x2F;local&#x2F;hadoop-3.1.4&#x2F;etc&#x2F;hadoop\nexport SPARK_MASTER_IP&#x3D;master\nexport SPARK_MASTER_PORT&#x3D;7077\nexport SPARK_WORKER_MEMORY&#x3D;512m\nexport SPARK_WORKER_CORES&#x3D;1\nexport SPARK_EXECUTOR_MEMORY&#x3D;512M\nexport SPARK_EXECUTOR_CORES&#x3D;1\nexport SPARK_WORKER_INSTANCES&#x3D;1</code></pre>\n\n\n\n<p>配置workers,删除原有内容</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">cp workers.template workers</code></pre>\n\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">slave1\nslave2</code></pre>\n\n\n\n<p>配置spark-defaults.conf</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">mv spark-defaults.conf.template spark-defaults.conf</code></pre>\n\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">spark.master    \t\t\t\tspark:&#x2F;&#x2F;master:7077\nspark.eventLog.enabled  \t\ttrue\nspark.eventLog.dir\t\t\t\thdfs:&#x2F;&#x2F;master:8020&#x2F;spark-logs\nspark.history.fs.logDirectory   hdfs:&#x2F;&#x2F;master:8020&#x2F;spark-logs</code></pre>\n\n\n\n<p>将主节点的spark安装目录发给从节点</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">scp -r &#x2F;usr&#x2F;local&#x2F;spark-3.2.1-bin-hadoop2.7&#x2F; slave1:&#x2F;usr&#x2F;local&#x2F;</code></pre>\n\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">scp -r &#x2F;usr&#x2F;local&#x2F;spark-3.2.1-bin-hadoop2.7&#x2F; slave2:&#x2F;usr&#x2F;local&#x2F;</code></pre>\n\n\n\n<p>启动hadoop集群</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">cd $HADOOP</code></pre>\n\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">sbin&#x2F;start-dfs.sh</code></pre>\n\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">sbin&#x2F;start-yarn.sh</code></pre>\n\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">sbin&#x2F;mr-jobhistory-daemon.sh start historyserver</code></pre>\n\n<p>创建spsark-logs目录</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">hdfs dfs -mkdir &#x2F;spark-logs</code></pre>\n\n<p>jps有以下内容：</p>\n<p>master：</p>\n<p>JobHistoryserver</p>\n<p>SecondaryNameNode</p>\n<p>Jps</p>\n<p>ResourceManager</p>\n<p>Namenode</p>\n<p>slave:</p>\n<p>DataNode</p>\n<p>NodeManager</p>\n<p>Jps</p>\n<p>启动spark</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">cd $SPARK_HOME&#x2F;sbin</code></pre>\n\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">.&#x2F;start-all.sh</code></pre>\n\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">.&#x2F;start-history-server.sh</code></pre>\n\n<p>jps,主节点有master，从节点有worker</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">http:&#x2F;&#x2F;master:8080</code></pre>\n\n","text":"安装带有图形化界面的centos7 配置好网络：vim /etc/sysconfig/network-scripts/ifcfg-ens33 更改hostname：hostnamectl set-hostname master 连接xshell与xftp，把所需要的spark和j...","link":"","photos":[],"count_time":{"symbolsCount":"3.6k","symbolsTime":"3 mins."},"categories":[{"name":"大数据开发","slug":"大数据开发","count":2,"path":"api/categories/大数据开发.json"}],"tags":[{"name":"spark","slug":"spark","count":1,"path":"api/tags/spark.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E6%90%AD%E5%BB%BA%E5%8D%95%E6%9C%BA%E7%89%88%E9%9B%86%E7%BE%A4\"><span class=\"toc-text\">搭建单机版集群</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E8%A7%A3%E5%8E%8Bspark%E5%AE%89%E8%A3%85%E5%8C%85\"><span class=\"toc-text\">解压spark安装包</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E6%90%AD%E5%BB%BA%E5%8D%95%E6%9C%BA%E4%BC%AA%E5%88%86%E5%BC%8F%E9%9B%86%E7%BE%A4\"><span class=\"toc-text\">搭建单机伪分式集群</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%88%A0%E9%99%A4centos%E8%87%AA%E5%B8%A6jdk\"><span class=\"toc-text\">删除centos自带jdk</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%AE%89%E8%A3%85jdk\"><span class=\"toc-text\">安装jdk</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#spark-env-sh\"><span class=\"toc-text\">spark-env.sh</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%90%AF%E5%8A%A8hadoop%E9%9B%86%E7%BE%A4\"><span class=\"toc-text\">启动hadoop集群</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E6%90%AD%E5%BB%BA%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4\"><span class=\"toc-text\">搭建完全分布式集群</span></a></li></ol>","author":{"name":"问天道","slug":"blog-author","avatar":"../source/img/titleImg.png","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"二叉树","uid":"563a71603f1af2b0a426978adee1756b","slug":"二叉树","date":"2023-04-11T04:02:29.000Z","updated":"2023-04-30T09:45:14.710Z","comments":true,"path":"api/articles/二叉树.json","keywords":null,"cover":[],"text":"专业术语度节点拥有的子树个数称为度 0&#x2F;1&#x2F;2 叶节点度(子树个数)为0的节点 分支节点度(子树个数)不为0的节点 叶节点外的其余节点都是分支节点 节点关系 A是B\\C的双亲 B是A的左孩子 C是A的右孩子 B&#x2F;C互称兄弟 A是D的祖先 D是A的子孙...","link":"","photos":[],"count_time":{"symbolsCount":266,"symbolsTime":"1 mins."},"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","count":1,"path":"api/categories/数据结构与算法.json"}],"tags":[{"name":"数据结构","slug":"数据结构","count":1,"path":"api/tags/数据结构.json"}],"author":{"name":"问天道","slug":"blog-author","avatar":"../source/img/titleImg.png","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"thinkpad x100e windows7重装","uid":"f41dafd82f2ec9dc49885e3686fd8f65","slug":"thinkpad-x100e-windows7重装","date":"2022-12-24T05:36:28.000Z","updated":"2023-04-30T09:44:15.383Z","comments":true,"path":"api/articles/thinkpad-x100e-windows7重装.json","keywords":null,"cover":null,"text":"一台 10 年的老电脑 MSDN，我告诉你：下载系统镜像准备另一台电脑，进入网站MSDN,我告诉你，下载对应镜像到自定义文件夹中(非 U 盘) 启动盘制作下载 启动盘制作工具-rufus下载完成后，插入 U 盘 打开软件的下载路径，双击打开 rufus-3.21.exe 在 ru...","link":"","photos":[],"count_time":{"symbolsCount":505,"symbolsTime":"1 mins."},"categories":[{"name":"其他","slug":"其他","count":1,"path":"api/categories/其他.json"}],"tags":[{"name":"windows7","slug":"windows7","count":1,"path":"api/tags/windows7.json"},{"name":"thinkpad x100e","slug":"thinkpad-x100e","count":1,"path":"api/tags/thinkpad-x100e.json"}],"author":{"name":"问天道","slug":"blog-author","avatar":"../source/img/titleImg.png","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}