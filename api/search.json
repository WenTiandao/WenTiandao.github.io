[{"id":"fa8d416a37bbc6136857104b4a6769f9","title":"控制台实现简单五子棋","content":"有（废）话要说这是我的第一个简单控制台项目，只实现了一些简单的功能，由于水平太差，如果您有建议，我会积极吸取改进，感激不尽。\n1 技术要求C语言数组、函数\n2 功能菜单：1.开始游戏2.设置3.退出\n点击开始游戏，加载地图。黑棋先落子，任意一方连成五子后，打印该方胜利，返回菜单。\n棋盘:map[i][j]表示坐标(i, j)的值0表示空地1表示黑子2表示白子\n回合数 : flag表示当前的回合数  偶数表示黑子，奇数表示白子\n3 代码实现#include&lt;stdio.h&gt;\n#include&lt;stdlib.h&gt;\n#include&lt;string.h&gt;\n\nint map[19][19];\nint flag;\n\nvoid init();\nvoid showMenu();\nvoid showMap();\nint playerMove(int x,int y);\nint isWin(int x,int y);\nvoid showWin();\nvoid playGame();\n\nint main()&#123;\n    showMenu();\n\n&#125;\n\nvoid playGame()&#123;\n    init();\n    while (1) &#123;\n        int x, y;\n        system(&quot;cls&quot;);\n        showMap();\n        printf(&quot;请输入落子位置：&quot;);\n        scanf(&quot;%d %d&quot;, &amp;x, &amp;y);\n        if (playerMove(x, y)&#x3D;&#x3D;0) &#123;\n            continue;\n        &#125;\n        if (isWin(x, y)) &#123;\n            showWin();\n        &#125;\n        flag++;\n    &#125;\n&#125;\n\n\n&#x2F;&#x2F;初始化数据\nvoid init()&#123;\n    flag&#x3D;0;\n    &#x2F;&#x2F;数组初始化为0；\n    memset(map,0,sizeof(map));\n&#125;\n\nvoid showMenu()&#123;\n    int choice;\n    printf(&quot;1.开始游戏\\n&quot;);\n    printf(&quot;2.设置\\n&quot;);\n    printf(&quot;3.退出游戏\\n&quot;);\n    printf(&quot;请输入选择：\\n&quot;);\n    scanf(&quot;%d&quot;, &amp;choice);\n    switch(choice)&#123;\n        case 1:\n            playGame();\n            break;\n        case 2:\n            printf(&quot;敬请期待...\\n&quot;);\n            showMenu();\n            break;\n        case 3:\n            exit(0);\n        default:\n            printf(&quot;输入有误请重新输入：\\n&quot;);\n            showMenu();\n    &#125;\n&#125;\n\nvoid showMap()&#123;\n    for (int i &#x3D; 0; i &lt; 19; i++) &#123;\n        for (int j &#x3D; 0; j &lt; 19; j++) &#123;\n            if (map[i][j] &#x3D;&#x3D; 0) &#123;\n                printf(&quot;+ &quot;);\n            &#125;\n            &#x2F;&#x2F;1表示黑子\n            else if (map[i][j] &#x3D;&#x3D; 1) &#123;\n                printf(&quot;● &quot;);\n            &#125;\n            &#x2F;&#x2F;2表示白子\n            else if (map[i][j] &#x3D;&#x3D; 2) &#123;\n                printf(&quot;o &quot;);\n            &#125;\n        &#125;\n        printf(&quot;\\n&quot;);\n    &#125;\n&#125;\n\nint playerMove(int x, int y)&#123;\n    if (map[x][y] &#x3D;&#x3D; 0) &#123;\n        if (flag % 2 &#x3D;&#x3D; 0) &#123;\n            map[x][y] &#x3D; 1;\n        &#125;else if (flag % 2 &#x3D;&#x3D; 1) &#123;\n            map[x][y] &#x3D; 2;\n        &#125;\n        return 1;\n    &#125;else &#123;\n        return 0;\n    &#125; \n&#125;\n\nint isWin(int x,int y)&#123;\n    &#x2F;&#x2F;横向判断\n    int count &#x3D; 0;\n    for (int i &#x3D; y - 4; i &lt;&#x3D; y + 4; i++)\n    &#123;\n        if (map[x][i] &#x3D;&#x3D; (flag % 2 + 1)) &#123;\n            count++;\n        &#125;\n    &#125;\n    if (count &#x3D;&#x3D; 5) &#123;\n        if (flag % 2 &#x3D;&#x3D; 0) &#123;\n            return 1;\n        &#125;else if (flag % 2&#x3D;&#x3D;1) &#123;\n            return 2;\n        &#125;\n    &#125;\n    &#x2F;&#x2F;纵向判断\n    count &#x3D; 0;\n    for (int i &#x3D; x - 4; i &lt;&#x3D; x + 4; i++)\n    &#123;\n        if (map[i][y] &#x3D;&#x3D; (flag % 2 + 1)) &#123;\n            count++;\n        &#125;\n    &#125;\n    if (count &#x3D;&#x3D; 5) &#123;\n        if (flag % 2 &#x3D;&#x3D; 0) &#123;\n            return 1;\n        &#125;\n        else if (flag % 2 &#x3D;&#x3D; 1) &#123;\n            return 2;\n        &#125;\n    &#125;\n    &#x2F;&#x2F;主对角线判断\n    count &#x3D; 0;\n    for (int i &#x3D; x - 4, j &#x3D; y - 4; i &lt;&#x3D; x + 4 &amp;&amp; j &lt;&#x3D; x + 4; i++, j++)\n    &#123;\n        if (map[i][j] &#x3D;&#x3D; (flag % 2 + 1)) &#123;\n            count++;\n        &#125;\n    &#125;\n    if (count &#x3D;&#x3D; 5) &#123;\n        if (flag % 2 &#x3D;&#x3D; 0) &#123;\n            return 1;\n        &#125;\n        else if (flag % 2 &#x3D;&#x3D; 1) &#123;\n            return 2;\n        &#125;\n    &#125;\n    &#x2F;&#x2F;副对角线判断\n    count &#x3D; 0;\n    for (int i &#x3D; x - 4, j &#x3D; y + 4; i &lt;&#x3D; x + 4 &amp;&amp; j &gt;&#x3D; y - 4; i++, j--)\n    &#123;\n        if (map[i][j] &#x3D;&#x3D; (flag % 2 + 1)) &#123;\n            count++;\n        &#125;\n    &#125;\n    if (count &#x3D;&#x3D; 5) &#123;\n        if (flag % 2 &#x3D;&#x3D; 0) &#123;\n            return 1;\n        &#125;\n        else if (flag % 2 &#x3D;&#x3D; 1) &#123;\n            return 2;\n        &#125;\n    &#125;\n    return 0;\n&#125;\n\nvoid showWin()&#123;\n    system(&quot;cls&quot;);\n    if (flag % 2 &#x3D;&#x3D; 0) &#123;\n        printf(&quot;---黑子胜利---&quot;);\n    &#125;else if (flag % 2 &#x3D;&#x3D; 1) &#123;\n        printf(&quot;---白子胜利---&quot;);\n    &#125;\n    printf(&quot;按任意键返回主菜单&quot;);\n    getchar(); \n    getchar();\n    system(&quot;cls&quot;);\n    showMenu();\n&#125;\n4 演示\n","slug":"控制台实现简单五子棋","date":"2023-11-17T07:54:14.000Z","categories_index":"","tags_index":"","author_index":"问天道"},{"id":"d843ced03f40ac612213952de4b63ad2","title":"二分查找","content":"704.给定一个 n 个元素有序的（升序）整型数组 nums 和一个目标值 target  ，写一个函数搜索 nums 中的 target，如果目标值存在返回下标，否则返回 -1。\n边界问题1 左闭右闭[left,right]int search(int* nums, int numsSize, int target) &#123;\n    int left&#x3D;0,right&#x3D;numsSize-1; \n    while(left&lt;&#x3D;right)&#123; \n        int middle&#x3D;(left+right)&#x2F;2;\n        if(nums[middle]&lt;target)&#123;\n            left&#x3D;middle+1; \n        &#125;else if(nums[middle]&gt;target)&#123; \n            right&#x3D;middle-1; \n        &#125;else&#123;\n            return middle; \n        &#125; \n    &#125; \n    return -1; \n&#125;\n\n2 左闭右开[left,right)int search(int* nums, int numsSize, int target) &#123;\n    int left&#x3D;0,right&#x3D;numsSize-1; \n    while(left&lt;right)&#123; \n        int middle&#x3D;(left+right)&#x2F;2;\n        if(nums[middle]&lt;target)&#123;\n            left&#x3D;middle+1; \n        &#125;else if(nums[middle]&gt;target)&#123; \n            &#x2F;&#x2F;右开区间，本身就不包含右边界\n            right&#x3D;middle; \n        &#125;else&#123;\n            return middle; \n        &#125; \n    &#125; \n    return -1; \n&#125;\n","slug":"二分查找","date":"2023-11-17T07:46:14.000Z","categories_index":"算法进阶之路","tags_index":"二分查找","author_index":"问天道"},{"id":"12060df9f4a3beced7cb40b966b788ad","title":"”hadoop和spark单机伪分布式集群搭建“","content":" 配置网络：\nvi &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-ens33\n\n修改 bootproto&#x3D;static，onboot&#x3D;yes，并添加 IP 地址、网关、子网掩码和 DNS 信息\n重启网卡：\nsystemctl restart network\n\nxshell远程连接\nyum install -y epel-release\n\nyum install -y pdsh\n\n下载 hadoop-3.1.4.tar.gz  上传到&#x2F;opt目录下并解压 \ntar -xf hadoop-3.1.4.tar.gz\n\n\n\n\n下载jdk-8u281-linux-x64.rpm并上传到&#x2F;opt目录下，执行以下安装命令\n\nrpm -ivh jdk-8u281-linux-x64.rpm\n\nvi &#x2F;opt&#x2F;hadoop-3.1.4&#x2F;etc&#x2F;hadoop&#x2F;hadoop-env.sh\n\nexport JAVA_HOME&#x3D;&#x2F;usr&#x2F;java&#x2F;jdk1.8.0_281-amd64&#x2F;\n\nvi &#x2F;opt&#x2F;hadoop-3.1.4&#x2F;etc&#x2F;hadoop&#x2F;core-site.xml\n\n&lt;configuration&gt;\n&lt;property&gt;\n        &lt;name&gt;fs.defaultFS&lt;&#x2F;name&gt;\n        &lt;value&gt;hdfs:&#x2F;&#x2F;localhost:9000&lt;&#x2F;value&gt;\n&lt;&#x2F;property&gt;\n&lt;&#x2F;configuration&gt;\n\n\n\nvi &#x2F;opt&#x2F;hadoop-3.1.4&#x2F;etc&#x2F;hadoop&#x2F;hdfs-site.xml\n\n&lt;configuration&gt;\n&lt;property&gt;\n    &lt;name&gt;dfs.replication&lt;&#x2F;name&gt;\n    &lt;value&gt;1&lt;&#x2F;value&gt;\n&lt;&#x2F;property&gt;\n&lt;&#x2F;configuration&gt;\n\nssh-keygen\n\ncat ~&#x2F;.ssh&#x2F;id_rsa.pub &gt;&gt; ~&#x2F;.ssh&#x2F;authorized_keys\n\nchmod 600 ~&#x2F;.ssh&#x2F;authorized_keys\n\nssh localhost\n\ncd &#x2F;opt&#x2F;hadoop-3.1.4\n\nbin&#x2F;hdfs namenode -format\n\nsbin&#x2F;start-dfs.sh\n\nvi &#x2F;etc&#x2F;profile\n\nexport HDFS_NAMENODE_USER&#x3D;root\nexport HDFS_DATANODE_USER&#x3D;root\nexport HDFS_SECONDARYNAMENODE_USER&#x3D;root\nexport YARN_RESOURCEMANAGER_USER&#x3D;root\nexport YARN_NODEMANAGER_USER&#x3D;root\n\nsource &#x2F;etc&#x2F;profile\n\nsbin&#x2F;start-dfs.sh\n","slug":"hadoop和spark单机伪分布式集群搭建","date":"2023-05-05T07:03:36.000Z","categories_index":"","tags_index":"","author_index":"问天道"},{"id":"3a5edbaf2fab1786cda1ddc2eee70e29","title":"进制转换","content":"信息在计算机中的表示进制转换R进制→十进制$$R进制数:k_{n}k_{n-1}k_{n-2}…k_{2}k_{1}k_{0}k_{-1}k_{-2}…k_{-m}$$\n$$V(R)&#x3D;k_{n}r^{n}+k_{n-1}r^{n-1}+k_{n-2}r^{n-2}…+k_{2}r^{2}+k_{1}r^{1}+k_{0}r^{0}+k_{-1}r^{-1}+k_{-2}r^{-2}…+k_{m}r^{m}$$\n十进制→R进制\n\n\n\n整数部分\n小数部分\n\n\n\n操作\n除以r(基)\n乘r\n\n\n余数\n低位\n高位\n\n\n\n⬆️\n⬇️\n\n\n\n高位\n低位\n\n\n二进制⇄八进制&#x2F;十六进制$$2^3&#x3D;8,因此每三位二进制数可以用来存取八进制数$$\n$$2^4&#x3D;16,因此每四位二进制数可以用来存取十六进制数$$\nBCD(8426)码用四位二进制数表示一位十进制\n计算题","slug":"进制转换","date":"2023-04-30T09:45:52.000Z","categories_index":"计算机组成原理","tags_index":"数据处理,进制转换","author_index":"问天道"},{"id":"563a71603f1af2b0a426978adee1756b","title":"二叉树","content":"专业术语度节点拥有的子树个数称为度 0&#x2F;1&#x2F;2\n叶节点度(子树个数)为0的节点\n分支节点度(子树个数)不为0的节点\n叶节点外的其余节点都是分支节点\n节点关系\n\nA是B\\C的双亲\nB是A的左孩子\nC是A的右孩子\nB&#x2F;C互称兄弟\nA是D的祖先\nD是A的子孙\n路径&#x2F;层&#x2F;深度\n\nABD是一条路径，路径长度为2\nA的层数为1，B的层数为2\n树的深度(最大层数)为2\n二叉树的形态基本形态5种形态\n\n\n满二叉树\n\n完全二叉树\n\n遍历先序遍历中序遍历后序遍历表达式前缀表达式中缀表达式后缀表达式","slug":"二叉树","date":"2023-04-11T04:02:29.000Z","categories_index":"数据结构与算法","tags_index":"数据结构","author_index":"问天道"},{"id":"e4350603b93fc89bd9ff79c0cc5af1e6","title":"spark集群搭建","content":"安装带有图形化界面的centos7\n配置好网络：vim /etc/sysconfig/network-scripts/ifcfg-ens33\n更改hostname：hostnamectl set-hostname master\n连接xshell与xftp，把所需要的spark和jdk安装包传输到&#x2F;opt目录\n搭建单机版集群解压spark安装包tar -zxf &#x2F;opt&#x2F;spark-3.2.1-bin-hadoop2.7.tgz -C &#x2F;usr&#x2F;local\n\n解压完成后单机版集群搭建成功\n进入spark安装目录的&#x2F;bin，计算Pi值\ncd &#x2F;usr&#x2F;local&#x2F;spark-3.2.1-bin-hadoop2.7&#x2F;bin&#x2F;\n.&#x2F;run-example SparkPi 2\n\n搭建单机伪分式集群删除centos自带jdk完成上一步后，需要安装jdk环境。由于带有图形化界面的centos自带openjdk，因此我们需要卸载原有的jdk，安装我们所需要的jdk文件。否则将导致jps无法执行：提示command not find\n[Linux执行jps命令的时候报错：-bash: jps: command not found - battleoutside - 博客园 \nrpm -qa | grep java #查看java文件\n\nsudo rpm -qa | grep java | xargs rpm -e --nodeps #root权限下删除所有java文件\n\n安装jdkrpm -ivh jdk-8u281-linux-x64.rpm\n\n检验\njava -version\n\n若出错，卸载jdk相关内容重新安装并检查：\n查看已安装jdk\nrpm -qa|grep jdk\n\n卸载列出的jdk\nsudo yum -y remove 路径1 路径2\n\n配置Java环境变量\n&#x2F;etc&#x2F;profile\nexport JAVA_HOME&#x3D;&#x2F;usr&#x2F;java&#x2F;jdk1.8.0_281-amd64\nexport PATH&#x3D;$PATH:$JAVA_HOME&#x2F;bin\n\n记得source\nspark-env.sh进入spark安装目录下的&#x2F;conf\ncd &#x2F;usr&#x2F;local&#x2F;spark-3.2.1-bin-hadoop2.7&#x2F;conf\n\n将spark-env.sh.template复制为spark-env.s，y\ncp spark-env.sh.template spark-env.sh\n\n在文件末尾spark-env.sh添加:（在此之前需更改hostname为master,否则计算时会报错）\nexport JAVA_HOME&#x3D;&#x2F;usr&#x2F;java&#x2F;jdk1.8.0_281-amd64\nexport HADOOP_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;hadoop-3.1.4\nexport HADOOP_CONF_DIR&#x3D;&#x2F;usr&#x2F;local&#x2F;hadoop-3.1.4&#x2F;etc&#x2F;hadoop\nexport SPARK_MASTER_IP&#x3D;master\nexport SPARK_LOCAL_IP&#x3D;master\n\n启动hadoop集群切换到spark安装目录下的&#x2F;sbin目录\ncd &#x2F;usr&#x2F;local&#x2F;spark-3.2.1-bin-hadoop2.7&#x2F;sbin\n\n.&#x2F;start-all.sh\n\njps &#x2F;&#x2F;若未安装jdk则显示command not found\n\n进入spark安装目录的&#x2F;bin，计算Pi值\ncd &#x2F;usr&#x2F;local&#x2F;spark-3.2.1-bin-hadoop2.7&#x2F;bin&#x2F;\n.&#x2F;run-example SparkPi 2\n\n搭建完全分布式集群 首先完成hadoop集群的搭建，一个master、两个slave\n配置环境变量：\nvim &#x2F;etc&#x2F;profile\n\nexport SPARK_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;spark-3.2.1-bin-hadoop2.7\nexport PATH&#x3D;$PATH:$SPARK_HOME&#x2F;bin\n\nsource &#x2F;etc&#x2F;profile\n\n\n\n修改spark-env.sh，注意删除或注释上单机伪分布集群的配置，不然jps：slave的worker不启动\ncd $SPARK_HOME&#x2F;conf\n\ncp spark-env.sh.template spark-env.sh\n\nexport JAVA_HOME&#x3D;&#x2F;usr&#x2F;java&#x2F;jdk1.8.0_281-amd64\nexport HADOOP_CONF_DIR&#x3D;&#x2F;usr&#x2F;local&#x2F;hadoop-3.1.4&#x2F;etc&#x2F;hadoop\nexport SPARK_MASTER_IP&#x3D;master\nexport SPARK_MASTER_PORT&#x3D;7077\nexport SPARK_WORKER_MEMORY&#x3D;512m\nexport SPARK_WORKER_CORES&#x3D;1\nexport SPARK_EXECUTOR_MEMORY&#x3D;512M\nexport SPARK_EXECUTOR_CORES&#x3D;1\nexport SPARK_WORKER_INSTANCES&#x3D;1\n\n\n\n配置workers,删除原有内容\ncp workers.template workers\n\nslave1\nslave2\n\n\n\n配置spark-defaults.conf\nmv spark-defaults.conf.template spark-defaults.conf\n\nspark.master    \t\t\t\tspark:&#x2F;&#x2F;master:7077\nspark.eventLog.enabled  \t\ttrue\nspark.eventLog.dir\t\t\t\thdfs:&#x2F;&#x2F;master:8020&#x2F;spark-logs\nspark.history.fs.logDirectory   hdfs:&#x2F;&#x2F;master:8020&#x2F;spark-logs\n\n\n\n将主节点的spark安装目录发给从节点\nscp -r &#x2F;usr&#x2F;local&#x2F;spark-3.2.1-bin-hadoop2.7&#x2F; slave1:&#x2F;usr&#x2F;local&#x2F;\n\nscp -r &#x2F;usr&#x2F;local&#x2F;spark-3.2.1-bin-hadoop2.7&#x2F; slave2:&#x2F;usr&#x2F;local&#x2F;\n\n\n\n启动hadoop集群\ncd $HADOOP\n\nsbin&#x2F;start-dfs.sh\n\nsbin&#x2F;start-yarn.sh\n\nsbin&#x2F;mr-jobhistory-daemon.sh start historyserver\n\n创建spsark-logs目录\nhdfs dfs -mkdir &#x2F;spark-logs\n\njps有以下内容：\nmaster：\nJobHistoryserver\nSecondaryNameNode\nJps\nResourceManager\nNamenode\nslave:\nDataNode\nNodeManager\nJps\n启动spark\ncd $SPARK_HOME&#x2F;sbin\n\n.&#x2F;start-all.sh\n\n.&#x2F;start-history-server.sh\n\njps,主节点有master，从节点有worker\nhttp:&#x2F;&#x2F;master:8080\n\n","slug":"spark集群搭建","date":"2023-02-17T12:01:41.000Z","categories_index":"大数据开发","tags_index":"spark","author_index":"问天道"},{"id":"f41dafd82f2ec9dc49885e3686fd8f65","title":"thinkpad x100e windows7重装","content":"一台 10 年的老电脑\nMSDN，我告诉你：下载系统镜像准备另一台电脑，进入网站MSDN,我告诉你，下载对应镜像到自定义文件夹中(非 U 盘)\n启动盘制作下载 启动盘制作工具-rufus下载完成后，插入 U 盘\n打开软件的下载路径，双击打开 rufus-3.21.exe\n在 rufus 中，选择下载好的 windows7 镜像文件(.iso)。分区类型改为 MBR点击开始，静待下方提示完成\n启动盘制作完成后，插入 u 盘到需要重装的笔记本电脑中。在开机期间连续按 Enter键，直到显示 Startup Interrupt Menu（启动中断菜单）官网进入 BIOS 方法。按照提示按 F1 进入 BIOS。\n进入 boot(不同型号大同小异)，按F5/F6键上下切换，将 USB HDD 切换到第一个，按F10键保存并退出 官方视频教学 第 36 秒退出后将自动进入重装界面，或自行开机进入\n重装按提示点击即可,期间重启无需操作，等待安装完成如不想设置密码直接点击下一步自行搜索 windows7 产品密钥，或直接点击下一步使用推荐设置\n安装完成后若缺少驱动，前往驱动精灵官网下载驱动精灵，安装缺失驱动\n","slug":"thinkpad-x100e-windows7重装","date":"2022-12-24T05:36:28.000Z","categories_index":"其他","tags_index":"windows7,thinkpad x100e","author_index":"问天道"},{"id":"9586898e5a198e00a7873bf32843aa83","title":"轮播图的两种实现方式:切换与平移","content":"","slug":"轮播图的两种实现方式-切换与平移","date":"2022-12-08T16:00:00.000Z","categories_index":"前端开发","tags_index":"Javascript","author_index":"问天道"},{"id":"4e4f31add73d915abf83a9e83faf2202","title":"hadoop-集群搭建","content":"设置固定 IPNAT 模式接入网络，要检查 windows 中网卡是否开启，并在属性中更改 ipv4 的配置信息\n\n在虚拟机中的虚拟网络编辑器中,更改子网为所需要的 128 网段\n\n\n在 master 中修改网卡配置文件：\nvim &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-ens33\n\n修改 bootproto&#x3D;static，onboot&#x3D;yes，并添加 IP 地址、网关、子网掩码和 DNS 信息。重启网卡服务：\nservice network restart\n&#x2F;&#x2F;systemctl restart network\n\n修改主机名hostnamectl set-hostname master\n\nxshell xftp 远程连接虚拟机NETSARANG 免费的许可证\n若出现远程连接慢，执行以下操作：\nvim &#x2F;etc&#x2F;ssh&#x2F;sshd_config\n\n\t#UseDNS yes ---&gt;默认为注释行\n\n\tUseDNS no ---&gt;把注释打开，改为no，然后重启ssh服务即可\nsystemctl restart sshd\n\n如果操作一切正常仍然连接不上，请检查vm相关服务是否开启以及是否开启自启动\n配置本地 yum 源进入&#x2F;etc&#x2F;yum.repos.d\ncd &#x2F;etc&#x2F;yum.repos.d\n\n禁用除了本地 yum 源 ：CentOS-Media.repo 以外的其他源，加文件名后缀.bak\nmv CentOS-Debuginfo.repo CentOS-Debuginfo.repo.bak\n\nmv CentOS-Base.repo CentOS-Base.repo.bak\n\nmv CentOS-Vault.repo CentOS-Vault.repo.bak\n\nmv CentOS-CR.repo CentOS-CR.repo.bak\n\nmv CentOS-fasttrack.repo CentOS-fasttrack.repo.bak\n\nmv CentOS-Sources.repo CentOS-Sources.repo.bak\n\nmv CentOS-x86_64-kernel.repo CentOS-x86_64-kernel.repo.bak\n\n修改 CentOS-Media.repo 文件内容。将 baseurl 的值修改为“file:&#x2F;&#x2F;&#x2F;media&#x2F;”，将 gpgcheck 的值改为“0”，将 enabled 的值改为“1”。像这样：\nname&#x3D;CentOS-$releasever - Media\nbaseurl&#x3D;file:&#x2F;&#x2F;&#x2F;media&#x2F;\ngpgcheck&#x3D;0\nenabled&#x3D;1\ngpgkey&#x3D;file:&#x2F;&#x2F;&#x2F;etc&#x2F;pki&#x2F;rpm-gpg&#x2F;RPM-GPG-KEY-CentOS-7\n\n\n确保开启\"已连接\"\n\n使用\n\nmount &#x2F;dev&#x2F;sr0 &#x2F;media\n\n命令挂载本地 YUM 源。提示写保护则挂载成功。清理 yum 缓存\nyum clean all\n\n使用 yum 安装常用软件yum install -y vim zip openssh-server openssh-clients\n安装 Java下载 jdk 的 npm 包(以 jdk-8u281-linux-x64.rpm 为例)，使用 xfpt 传输到&#x2F;opt 目录下\n切换到&#x2F;opt，使用命令安装 jdk\nrpm -ivh jdk-8u281-linux-x64.rpm\n\n验证是否安装成功\njava -version\n\n安装 Hadoop 修改集群相关配置文件将 Hadoop 安装包 hadoop-3.1.4.tar.gz 上传至虚拟机 master 的&#x2F;opt 目录下，进入&#x2F;opt使用tar解压至&#x2F;usr&#x2F;local：\ntar -zxf hadoop-3.1.4.tar.gz -C &#x2F;usr&#x2F;local\n\n进入/usr/local/hadoop-3.1.4/etc/hadoop 目录：\ncd &#x2F;usr&#x2F;local&#x2F;hadoop-3.1.4&#x2F;etc&#x2F;hadoop\n\n并修改 core-site.xml、hadoop-env.sh、yarn-env.sh、mapred-site.xml、yarn-site.xml、workers、hdfs-site.xml 共 7 个配置文件的内容。\ncore-site.xml\n&lt;configuration&gt;\n    &lt;property&gt;\n    &lt;name&gt;fs.defaultFS&lt;&#x2F;name&gt;\n      &lt;value&gt;hdfs:&#x2F;&#x2F;master:8020&lt;&#x2F;value&gt;\n      &lt;&#x2F;property&gt;\n    &lt;property&gt;\n      &lt;name&gt;hadoop.tmp.dir&lt;&#x2F;name&gt;\n      &lt;value&gt;&#x2F;var&#x2F;log&#x2F;hadoop&#x2F;tmp&lt;&#x2F;value&gt;\n    &lt;&#x2F;property&gt;\n&lt;&#x2F;configuration&gt;\n\nhadoop-env.sh\nexport JAVA_HOME&#x3D;&#x2F;usr&#x2F;java&#x2F;jdk1.8.0_281-amd64\n&#x2F;&#x2F;修改 JAVA_HOME 的值为 JDK 所在目录（注意版本，确保文件名正确&#x2F;usr&#x2F;java&#x2F;...）\n&#x2F;&#x2F;(文件内高亮查找:&#x2F;JAVA_HOME)\n\nyarn-env.sh\n#export JAVA_HOME&#x3D;&#x2F;home&#x2F;y&#x2F;libexec&#x2F;jdk1.6.0&#x2F;\nexport JAVA_HOME&#x3D;&#x2F;usr&#x2F;java&#x2F;jdk1.8.0_281-amd64\n\nmapred-site.xml\n&lt;configuration&gt;\n&lt;property&gt;\n    &lt;name&gt;mapreduce.framework.name&lt;&#x2F;name&gt;\n    &lt;value&gt;yarn&lt;&#x2F;value&gt;\n&lt;&#x2F;property&gt;\n&lt;!-- jobhistory properties --&gt;\n&lt;property&gt;\n    &lt;name&gt;mapreduce.jobhistory.address&lt;&#x2F;name&gt;\n    &lt;value&gt;master:10020&lt;&#x2F;value&gt;\n&lt;&#x2F;property&gt;\n&lt;property&gt;\n     &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;&#x2F;name&gt;\n     &lt;value&gt;master:19888&lt;&#x2F;value&gt;\n&lt;&#x2F;property&gt;\n&lt;property&gt;\n  &lt;name&gt;yarn.app.mapreduce.am.env&lt;&#x2F;name&gt;\n  &lt;value&gt;HADOOP_MAPRED_HOME&#x3D;$&#123;HADOOP_HOME&#125;&lt;&#x2F;value&gt;\n&lt;&#x2F;property&gt;\n&lt;property&gt;\n  &lt;name&gt;mapreduce.map.env&lt;&#x2F;name&gt;\n  &lt;value&gt;HADOOP_MAPRED_HOME&#x3D;$&#123;HADOOP_HOME&#125;&lt;&#x2F;value&gt;\n&lt;&#x2F;property&gt;\n&lt;property&gt;\n  &lt;name&gt;mapreduce.reduce.env&lt;&#x2F;name&gt;\n  &lt;value&gt;HADOOP_MAPRED_HOME&#x3D;$&#123;HADOOP_HOME&#125;&lt;&#x2F;value&gt;\n&lt;&#x2F;property&gt;\n&lt;&#x2F;configuration&gt;\n\nyarn-site.xml\n&lt;configuration&gt;\n&lt;!-- Site specific YARN configuration properties --&gt;\n&lt;property&gt;\n    &lt;name&gt;yarn.resourcemanager.hostname&lt;&#x2F;name&gt;\n    &lt;value&gt;master&lt;&#x2F;value&gt;\n  &lt;&#x2F;property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.resourcemanager.address&lt;&#x2F;name&gt;\n    &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8032&lt;&#x2F;value&gt;\n  &lt;&#x2F;property&gt;\n &lt;property&gt;\n    &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;&#x2F;name&gt;\n    &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8030&lt;&#x2F;value&gt;\n  &lt;&#x2F;property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.resourcemanager.webapp.address&lt;&#x2F;name&gt;\n    &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8088&lt;&#x2F;value&gt;\n  &lt;&#x2F;property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.resourcemanager.webapp.https.address&lt;&#x2F;name&gt;\n    &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8090&lt;&#x2F;value&gt;\n  &lt;&#x2F;property&gt;\n&lt;property&gt;\n    &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;&#x2F;name&gt;\n    &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8031&lt;&#x2F;value&gt;\n  &lt;&#x2F;property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.resourcemanager.admin.address&lt;&#x2F;name&gt;\n    &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8033&lt;&#x2F;value&gt;\n  &lt;&#x2F;property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.nodemanager.local-dirs&lt;&#x2F;name&gt;\n    &lt;value&gt;&#x2F;data&#x2F;hadoop&#x2F;yarn&#x2F;local&lt;&#x2F;value&gt;\n  &lt;&#x2F;property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.log-aggregation-enable&lt;&#x2F;name&gt;\n    &lt;value&gt;true&lt;&#x2F;value&gt;\n  &lt;&#x2F;property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.nodemanager.remote-app-log-dir&lt;&#x2F;name&gt;\n    &lt;value&gt;&#x2F;data&#x2F;tmp&#x2F;logs&lt;&#x2F;value&gt;\n  &lt;&#x2F;property&gt;\n&lt;property&gt;\n &lt;name&gt;yarn.log.server.url&lt;&#x2F;name&gt;\n &lt;value&gt;http:&#x2F;&#x2F;master:19888&#x2F;jobhistory&#x2F;logs&#x2F;&lt;&#x2F;value&gt;\n &lt;description&gt;URL for job history server&lt;&#x2F;description&gt;\n&lt;&#x2F;property&gt;\n&lt;property&gt;\n   &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;&#x2F;name&gt;\n    &lt;value&gt;false&lt;&#x2F;value&gt;\n  &lt;&#x2F;property&gt;\n &lt;property&gt;\n    &lt;name&gt;yarn.nodemanager.aux-services&lt;&#x2F;name&gt;\n    &lt;value&gt;mapreduce_shuffle&lt;&#x2F;value&gt;\n  &lt;&#x2F;property&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;&#x2F;name&gt;\n      &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;&#x2F;value&gt;\n      &lt;&#x2F;property&gt;\n&lt;property&gt;\n        &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;&#x2F;name&gt;\n        &lt;value&gt;2048&lt;&#x2F;value&gt;\n &lt;&#x2F;property&gt;\n &lt;property&gt;\n        &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;&#x2F;name&gt;\n        &lt;value&gt;512&lt;&#x2F;value&gt;\n &lt;&#x2F;property&gt;\n &lt;property&gt;\n        &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;&#x2F;name&gt;\n        &lt;value&gt;4096&lt;&#x2F;value&gt;\n &lt;&#x2F;property&gt;\n &lt;property&gt;\n    &lt;name&gt;mapreduce.map.memory.mb&lt;&#x2F;name&gt;\n    &lt;value&gt;2048&lt;&#x2F;value&gt;\n &lt;&#x2F;property&gt;\n &lt;property&gt;\n    &lt;name&gt;mapreduce.reduce.memory.mb&lt;&#x2F;name&gt;\n    &lt;value&gt;2048&lt;&#x2F;value&gt;\n &lt;&#x2F;property&gt;\n &lt;property&gt;\n    &lt;name&gt;yarn.nodemanager.resource.cpu-vcores&lt;&#x2F;name&gt;\n    &lt;value&gt;1&lt;&#x2F;value&gt;\n &lt;&#x2F;property&gt;\n&lt;&#x2F;configuration&gt;\n\nworkers\n&#x2F;&#x2F;删除 localhost，添加以下内容\nslave1\nslave2\nslave3\n\nhdfs-site.xml\n&lt;configuration&gt;\n&lt;property&gt;\n    &lt;name&gt;dfs.namenode.name.dir&lt;&#x2F;name&gt;\n    &lt;value&gt;file:&#x2F;&#x2F;&#x2F;data&#x2F;hadoop&#x2F;hdfs&#x2F;name&lt;&#x2F;value&gt;\n&lt;&#x2F;property&gt;\n&lt;property&gt;\n    &lt;name&gt;dfs.datanode.data.dir&lt;&#x2F;name&gt;\n    &lt;value&gt;file:&#x2F;&#x2F;&#x2F;data&#x2F;hadoop&#x2F;hdfs&#x2F;data&lt;&#x2F;value&gt;\n&lt;&#x2F;property&gt;\n&lt;property&gt;\n     &lt;name&gt;dfs.namenode.secondary.http-address&lt;&#x2F;name&gt;\n     &lt;value&gt;master:50090&lt;&#x2F;value&gt;\n&lt;&#x2F;property&gt;\n&lt;property&gt;\n     &lt;name&gt;dfs.replication&lt;&#x2F;name&gt;\n     &lt;value&gt;3&lt;&#x2F;value&gt;\n&lt;&#x2F;property&gt;\n&lt;&#x2F;configuration&gt;\n\n为了防止 Hadoop 集群启动失败，需要修改 Hadoop 集群启动和关闭服务的文件。启动和关闭服务的文件在&#x2F;usr&#x2F;local&#x2F;hadoop-3.1.4&#x2F;sbin&#x2F;目录下，需要修改的文件分别是 start-dfs.sh、stop-dfs.sh、start-yarn.sh 和 stop-yarn.sh。\nstart-dfs.sh、stop-dfs.sh\nHDFS_DATANODE_USER&#x3D;root\nHDFS_DATANODE_SECURE_USER&#x3D;hdfs\nHDFS_NAMENODE_USER&#x3D;root\nHDFS_SECONDARYNAMENODE_USER&#x3D;root\n\nstart-yarn.sh 和 stop-yarn.sh\nYARN_RESOURCEMANAGER_USER&#x3D;root\nHADOOP_SECURE_DN_USER&#x3D;yarn\nYARN_NODEMANAGER_USER&#x3D;root\n\n修改主机与 IP 地址映射 &#x2F;etc&#x2F;hosts\n192.168.128.130 master master.centos.com\n192.168.128.131 slave1 salve1.centos.com\n192.168.128.132 slave2 slave2.centos.com\n192.168.128.133 slave3 slave3.centos.com\n\n克隆虚拟机创建 master 的完整克隆 slave1、slave2、slave3分别修改网卡配置文件和主机名\nvim &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-ens33\n\nservice network restart\n\nhostnamectl set-hostname slave1\n\n验证是否配置成功，在 master 上 ping 一下各个节点\nping slave1\n\nping slave2\n\nping slave3\n\n配置 ssh 免密登录master 上创建 ssh 密钥，三次 enter 键\nssh-keygen -t rsa\n\n使用 ssh-copy-id 命令将公钥复制至远程机器中。按提示输入 yes 和密码\nssh-copy-id -i &#x2F;root&#x2F;.ssh&#x2F;id_rsa.pub master\n\nssh-copy-id -i &#x2F;root&#x2F;.ssh&#x2F;id_rsa.pub slave1\n\nssh-copy-id -i &#x2F;root&#x2F;.ssh&#x2F;id_rsa.pub slave2\n\nssh-copy-id -i &#x2F;root&#x2F;.ssh&#x2F;id_rsa.pub slave3\n\n验证 SSH 是否能够无密钥登录。在 master 主节点下分别输入“ssh slave1”“ssh slave2”“ssh slave3”\n配置时间同步服务检查 master 和各节点虚拟机是否连接\n在 master 和各节点重新挂在本地 yum 源\nmount &#x2F;dev&#x2F;sr0 &#x2F;media\n\n安装 ntp 服务\nyum install -y ntp\n\n修改 master 的&#x2F;etc&#x2F;ntp.conf 文件，注释掉以 server 开头的行，添加：\nrestrict 192.168.1.0 mask 255.255.255.0 nomodify notrap\nserver 127.127.1.0\nfudge 127.127.1.0 stratum 10\n\n修改 slave1、slave2、slave3 的&#x2F;etc&#x2F;ntp.conf 文件，注释掉 server 开头的行，并添加:server master\n关闭 master 和 slave1、slave2、slave3 防火墙\nsystemctl stop firewalld\n\nsystemctl disable firewalld\n\nsystemctl status firewalld\n\n &#x2F;&#x2F;状态为 dead\n在 master 启动 ntp\nsystemctl start ntpd\n\nsystemctl enable ntpd\n\nsystemctl status ntpd\n\n&#x2F;&#x2F;查看状态为 active 说明成功\nslave1、slave2、slave3 同步时间\nntpdate master\n\nslave1、slave2、slave3 启动 ntp\nsystemctl start ntpd\n\nsystemctl enable ntpd\n\nsystemctl status ntpd\n\n&#x2F;&#x2F;查看状态为 active 说明成功\n配置环境变量和格式化 NameNode在 master 和 slave1、slave2、slave3 修改&#x2F;etc&#x2F;profile 文件，注意文件版本名。使用 source /etc/profile 生效\nexport HADOOP_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;hadoop-3.1.4\nexport PATH&#x3D;$HADOOP_HOME&#x2F;bin:$PATH:$JAVA_HOME&#x2F;bin\n\n在 master 和 slave1、slave2、slave3 输入 hdfs namenode -format 格式化\n启动和关闭集群启动\ncd $HADOOP\n\nsbin&#x2F;start-dfs.sh\n\nsbin&#x2F;start-yarn.sh\n\nsbin&#x2F;mr-jobhistory-daemon.sh start historyserver\n\n关闭\ncd $HADOOP\n\nsbin&#x2F;stop-dfs.sh\n\nsbin&#x2F;stop-yarn.sh\n\nsbin&#x2F;mr-jobhistory-daemon.sh stop historyserver\n\n监控集群修改 windows 中的 C:\\Windows\\System32\\drivers\\etc\\hosts 文件(需要在属性中开启 user 的读写权限)\n192.168.128.130 master master.centos.com\n192.168.128.131 slave1 salve1.centos.com\n192.168.128.132 slave2 slave2.centos.com\n192.168.128.133 slave3 slave3.centos.com\n\n集群监控\nhttp://master:9870 &#x2F;&#x2F;hdfs 监控http://master:8088 &#x2F;&#x2F;yarn 监控http://master:19888 &#x2F;&#x2F;jobhistory 日志监控\n","slug":"HADOOP-集群搭建","date":"2022-11-07T16:00:00.000Z","categories_index":"大数据开发","tags_index":"hadoop","author_index":"问天道"},{"id":"0c98adb549c320eeb63bf21d0f37524f","title":"shell编程实践","content":"shell 编程实践使用 shell 编写杨辉三角\n\n回顾排列组合从 5 个人中抽取 3 个人参加会议(3 个人不能是同一个人，即无重复)\n① 有顺序\n则有 5×4×3 中可能(抽第一个 5 种,第二个 4 种，第三个 3 中(从剩下三个人中选))\n即从 n 个人中抽取 r 个人，一共有 n×(n-1)×…×(n-r)中可能\n即排列公式\n② 无顺序\n上面的抽取的三人中，我们给他们分别排了序号，即使是抽取的相同三人，也因为顺序不同是不同的情况。现在我们无序地抽取三人，则基于 5×4×3 的基础上，要去掉重复的情况，选取的三人有 3×2×1 种排序方式，因此需要除以重复的情况，得到不重复的抽取三人的方法数\n即组合公式\n回顾二项式定理1 _n-1&#x3D;0_，s&#x3D;2⁰&#x3D;0,(a+b)⁰&#x3D;1\n1 1 n-1&#x3D;1,s&#x3D;2¹&#x3D;2,(a+b)¹&#x3D;a+b\n1 2 1 n-1&#x3D;2,s&#x3D;2²,(a+b)²&#x3D;a²+2ab+b²\n1 3 3 1 n-1&#x3D;3,s&#x3D;2³,(a+b)³&#x3D;a³+3a²b+3ab²+b³\n1 4 6 4 1 n-1&#x3D;4,s&#x3D;2⁴,(a+b)⁴&#x3D;a⁴+4a³b+6a²b²+4ab³+b⁴\n1 5 10 10 5 1 n-1&#x3D;5,s&#x3D;2⁵,…\n**1 6 15 20 15 6 1 ** n-1&#x3D;6,s&#x3D;⁶,…\n二项式定理\n\n\n先看这个例子(x+y)³&#x3D;(x+y)(x+y)(x+y)\n三个式子相乘，可能的情况是：(从取 x 的角度看)\n\n\n\n第一项\n第二项\n第三项\n概率\n\n\n\nx\nx\nx\n三个都是 x：C₃³&#x3D;1\n\n\nx\nx\ny\n两个 x，一个 y：C₃²&#x3D;3\n\n\nx\ny\nx\n\n\n\ny\nx\nx\n\n\n\nx\ny\ny\n一个 x，两个 y：C₃¹&#x3D;3\n\n\ny\nx\ny\n\n\n\ny\ny\nx\n\n\n\ny\ny\ny\n取 0 个 x，3 个 y：C₃⁰&#x3D;1\n\n\n因此将(x+y)³&#x3D;(x+y)(x+y)(x+y)展开可以得到\n(x+y)³&#x3D;C₃⁰x⁰y³+C₃¹xy²+C₃²x²y+C₃³x³y⁰&#x3D;x³+3x²y+3xy²+y³\n因此在二项式定理中，展开以后有 n 项(a+b)相乘，假设从取 b 的角度看，可以全都不取 b(b⁰)、有一项取 b、两项取 b(b²)…m 项取 b(bm)，概率为 Cnm，故有\n\n\n杨辉三角中的关系① 每个数等于上面两个数之和，左右对称\n即C(n+1,i)&#x3D;C(n,i)+C(n,i-1)\n② 第 n 行有 n 项\n③ 前 n 行有 n(n+1)&#x2F;2 项，即 1+2+3+…+n\n回顾等差数列\n\n\n\n\n④ 第 n 行第 m 个数为 Cn-1m-1\n⑤ 第 n 行的第 m 个数和第 n-m+1 个数相等\n⑥ 第 n 行的数字和为 2n-1\n⑦ 二项式定理中(a+b)n的系数对应第 n+1 行的每一项\n⑧ 其他，如斐波那契数列\n使用 shell 编写杨辉三角#!&#x2F;bin&#x2F;bash\nread -p &quot;请输入行数:&quot; n\necho &quot;1&quot;\n#打印第一行的1\nfor((i&#x3D;2;i&lt;&#x3D;n;i++))\n#从第2行循环到第1行\ndo\n  s&#x3D;1\n  echo -e &quot;1 \\c&quot;\n  #打印每一行第一个1\n  for((j&#x3D;1;j&lt;&#x3D;i-2;j++))\n  #第i行除去首尾两个1还剩i-2个数，依次循环打印\n  do\n    k&#x3D;$(($i-$j))\n    s&#x3D;$(($k*$s&#x2F;$j))\n    echo -e &quot;$s \\c&quot;\n  done\n  echo 1\n  #打印每一行最后一个1\ndone\n\n首先观察这个规律，第 n 行第 m 项与第 m-1 项之间的倍数关系：\n① 第 m-1 项：Cn-1m-2&#x3D;(n-1)!&#x2F;(n-m+1)!(m-2)!\n② 第 m 项：Cn-1m-1&#x3D;(n-1)!&#x2F;(n-m)!(m-1)!\n②&#x2F;① 得(n-m+1)&#x2F;(m-1)\n而在上面得程序中，我们让 j 从 i 行的第 2 个数开始循环，即 j&#x3D;m-1\n因此我们可以得到上述程序中的前后倍数关系(i-j)&#x2F;j\n我们令每一行第一个式子为 s&#x3D;1，则每个式子都是前一个式子得(i-j)&#x2F;j 倍\n因此可以写成 s&#x3D;s*(i-j)&#x2F;j，通过循环我们就可以打印出每行得每个式子\n同时，你也可以写成这种形式\n#!&#x2F;bin&#x2F;bash\nread -p &quot;请输入行数:&quot; n\necho &quot;1&quot;\n#打印第一行的1\nfor((i&#x3D;2;i&lt;&#x3D;n;i++))\n#从第2行循环到第1行\ndo\n  s&#x3D;1\n  echo -e &quot;1 \\c&quot;\n  #打印每一行第一个1\n  for((j&#x3D;2;j&lt;&#x3D;i-1;j++))\n  #j为每行第j个数\n  do\n    k&#x3D;$(($i-$j+1))\n    m&#x3D;$(($j-1))\n    s&#x3D;$(($k*$s&#x2F;$m))\n    echo -e &quot;$s \\c&quot;\n  done\n  echo 1\n  #打印每一行最后一个1\ndone\n\n此时前后的倍数关系为(i-j+1)&#x2F;(j-1)\n现在让我们开始打印吧！\n①\n\n\n\n\n②\n\n\n\n\n编写脚本生成脚本要求执行脚本后，会自动生成一个 test.sh 脚本，并赋予执行权限，同时在文件中加入以下注释信息\n#!&#x2F;bin&#x2F;bash\n#--------------------\n#Filename:test.sh&#x2F;&#x2F;此处会根据文件名自动更换\n#Revison:1.0\n#Date:2022-04-23&#x2F;&#x2F;此处自动更新时间\n#Author：Fishyoung\n#--------------------\n#Copyright：2022Fishyoung\n\n\n\n使用重定向将文本内容加入到脚本中\n","slug":"shell","date":"2022-04-23T01:21:53.000Z","categories_index":"Linux","tags_index":"Linux,shell,脚本","author_index":"问天道"},{"id":"58b7f561a82cc9dd7c27d8845a6fb9dd","title":"git","content":"","slug":"git","date":"2022-01-18T00:00:00.000Z","categories_index":"note","tags_index":"git","author_index":"问天道"},{"id":"45b05c0adc7d6b51711d3e13e977b9ba","title":"hexo","content":"Hexo 中文官网\nNode.Js 官网\nGit 官网\n自行安装\n全局安装 Hexonpm install -g hexo-cli\n\n查看版本\nhexo -v\n\n文件夹初始化hexo init\n\n工具安装npm install hexo-server --save &#x2F;&#x2F;安装服务器启动工具\nnpm install hexo-deployer-git --save &#x2F;&#x2F;安装自动部署工具\n\n建立 Github 仓库name/ name.github.io\n勾选Add a README file\n远程连接 Github生成 ssh keys\nssh-keygen -t rsa -C &quot;email&quot; &#x2F;&#x2F;email指github注册邮箱\n\n查看，复制 ssh keys，添加至 GitHub\ncat ~&#x2F;.ssh&#x2F;id_rsa.pub\n\n测试是否成功：\nHi metaQ! You’ve successfully authenticated, but GitHub does not provide shell access.\nssh -T git@github.com\n\ngit 与 github 远程连接\ngit config --global user.name &quot;name&quot;\ngit config --global user.email &quot;email&quot;\n\n部署hexo s &#x2F;&#x2F;启动服务器，生成http:&#x2F;&#x2F;localhost:4000，启动期间自动更新\nhexo g &#x2F;&#x2F;生成静态文件\nhexo d &#x2F;&#x2F;部署到github\n\n常见问题4000 端口被占用netstat -aon|findstr &quot;4000&quot; &#x2F;&#x2F;查看被占用端口的PID（最后的数字即PID），以23828为例\ntasklist|findstr &quot;23828&quot; &#x2F;&#x2F;输入PID，查看占用进程的软件，以WinStore.App.exe为例\ntaskkill &#x2F;f &#x2F;t &#x2F;im WinStore.App.exe &#x2F;&#x2F;杀死进程\n\n图片无法显示npm install hexo-asset-image --save &#x2F;&#x2F;下载图片上传插件\n\n打开node_modules\\hexo-asset-image\\index.js，内容更改为以下代码：\n&#39;use strict&#39;;\nvar cheerio &#x3D; require(&#39;cheerio&#39;);\n\n&#x2F;&#x2F; http:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;14480345&#x2F;how-to-get-the-nth-occurrence-in-a-string\nfunction getPosition(str, m, i) &#123;\n  return str.split(m, i).join(m).length;\n&#125;\n\nvar version &#x3D; String(hexo.version).split(&#39;.&#39;);\nhexo.extend.filter.register(&#39;after_post_render&#39;, function(data)&#123;\n  var config &#x3D; hexo.config;\n  if(config.post_asset_folder)&#123;\n    \tvar link &#x3D; data.permalink;\n\tif(version.length &gt; 0 &amp;&amp; Number(version[0]) &#x3D;&#x3D; 3)\n\t   var beginPos &#x3D; getPosition(link, &#39;&#x2F;&#39;, 1) + 1;\n\telse\n\t   var beginPos &#x3D; getPosition(link, &#39;&#x2F;&#39;, 3) + 1;\n\t&#x2F;&#x2F; In hexo 3.1.1, the permalink of &quot;about&quot; page is like &quot;...&#x2F;about&#x2F;index.html&quot;.\n\tvar endPos &#x3D; link.lastIndexOf(&#39;&#x2F;&#39;) + 1;\n    link &#x3D; link.substring(beginPos, endPos);\n\n    var toprocess &#x3D; [&#39;excerpt&#39;, &#39;more&#39;, &#39;content&#39;];\n    for(var i &#x3D; 0; i &lt; toprocess.length; i++)&#123;\n      var key &#x3D; toprocess[i];\n\n      var $ &#x3D; cheerio.load(data[key], &#123;\n        ignoreWhitespace: false,\n        xmlMode: false,\n        lowerCaseTags: false,\n        decodeEntities: false\n      &#125;);\n\n      $(&#39;img&#39;).each(function()&#123;\n    \tif ($(this).attr(&#39;src&#39;))&#123;\n    \t\t&#x2F;&#x2F; For windows style path, we replace &#39;\\&#39; to &#39;&#x2F;&#39;.\n    \t\tvar src &#x3D; $(this).attr(&#39;src&#39;).replace(&#39;\\\\&#39;, &#39;&#x2F;&#39;);\n    \t\tif(!&#x2F;http[s]*.*|\\&#x2F;\\&#x2F;.*&#x2F;.test(src) &amp;&amp;\n    \t\t   !&#x2F;^\\s*\\&#x2F;&#x2F;.test(src)) &#123;\n    \t\t  &#x2F;&#x2F; For &quot;about&quot; page, the first part of &quot;src&quot; can&#39;t be removed.\n    \t\t  &#x2F;&#x2F; In addition, to support multi-level local directory.\n    \t\t  var linkArray &#x3D; link.split(&#39;&#x2F;&#39;).filter(function(elem)&#123;\n    \t\t\treturn elem !&#x3D; &#39;&#39;;\n    \t\t  &#125;);\n    \t\t  var srcArray &#x3D; src.split(&#39;&#x2F;&#39;).filter(function(elem)&#123;\n    \t\t\treturn elem !&#x3D; &#39;&#39; &amp;&amp; elem !&#x3D; &#39;.&#39;;\n    \t\t  &#125;);\n    \t\t  if(srcArray.length &gt; 1)\n    \t\t\tsrcArray.shift();\n    \t\t  src &#x3D; srcArray.join(&#39;&#x2F;&#39;);\n    \t\t  $(this).attr(&#39;src&#39;, config.root + link + src);\n    \t\t  console.info&amp;&amp;console.info(&quot;update link as:--&gt;&quot;+config.root + link + src);\n    \t\t&#125;\n    \t&#125;else&#123;\n    \t\tconsole.info&amp;&amp;console.info(&quot;no src attr, skipped...&quot;);\n    \t\tconsole.info&amp;&amp;console.info($(this));\n    \t&#125;\n      &#125;);\n      data[key] &#x3D; $.html();\n    &#125;\n\n  &#125;\n&#125;);\n\n将 _config.yml 文件中的 post_asset_folder 选项设为 true 来打开。 &#x2F;&#x2F;每次创建文章会生成同名文件夹，将图片存放在这个资源文件夹中\n\n&#123;% asset_img example.jpg 描述 %&#125; &#x2F;&#x2F;通过相对路径引用example.jpg图片\n\nVS Code 终端无法运行以管理员身份运行powershell\n输入set-ExecutionPolicy RemoteSigned\n输入A &#x2F;&#x2F;解决权限问题\n\nfatal: unable to access\n\n连接 github 不成功，不用担心，继续尝试吧！\ngithub 仓库存在两个分支deploy:\n  type: git\n  repository: 仓库网址\n  branch: main &#x2F;&#x2F;问题出在这里，若选择master，会新建一个master分支\n\ngithub pages build and deployment 失败显示\nerror：docker pull failed with code1\n解决方案：重新安装 hexo 部署工具\nnpm install hexo-deployer-git --save\n\nWarning: Accessing non-existent property ‘lineno’ of module exports inside circular dependency添加到 package.json\n&quot;resolutions&quot;: &#123;\n  &quot;stylus&quot;: &quot;^0.54.8&quot;\n&#125;\n\n执行\nnpm install --global yarn &#x2F;&#x2F;安装yarn\nyarn remove hexo-renderer-stylus\nyarn add hexo-renderer-stylus\n\nERROR Render HTML failed:\n\n\n\n\n\n\n\n\n\nUnhandled rejection ReferenceError: D:\\blog\\themes\\snail\\layout\\layout.ejs:1614| 15|\n\n\n\n\n\n\n\n\n\n\n\n16| &lt;%- partial(‘_partial&#x2F;header’,{cache: true}) %&gt;17|18| &lt;%- partial(‘_partial&#x2F;nav’,{cache: true}) %&gt;19|\n\n\n\n\n\n\n\n\n\n\n\nD:\\blog\\themes\\snail\\layout_partial\\header.ejs:7068| 69| \n\n\n\n\n\n\n\n\n\n\n\n70| Words &lt;%&#x3D; wordcount(page.content) %&gt; and71| Reading Time &lt;%&#x3D; min2read(page.content) %&gt; Minutes72| 73| \n\n\n\n错误指示 16，70，可以排查出是该主题的 hexo-wordcount 错误，以至于无法打开文章\ngithub 给出安装方法GitHub - willin&#x2F;hexo-wordcount: A Word Count Plugin for Hexo\nyarn add hexo-wordcount\n# or\nnpm i --save hexo-wordcount\n","slug":"HEXO","date":"2022-01-17T05:01:00.000Z","categories_index":"note","tags_index":"hexo","author_index":"问天道"}]